%- summarise chapters?
%- re-iterate take-home messages from introduction
%  - AR is more than just SLAM
%  - multi-view scene understanding is worthwhile
%  - geometry is helpful for scene understanding
%  - indoor Manhattan models are a good choice because
%    - simple
%    - concise
%    - general
%    - efficient inference possible

%- key results
%  - textons are a simple and flexible basis for scene context
%  - vanishing points should be estimated from multiple views if available
% - there is a simple and efficient inference algorithm for indoor Manhattan models
%  - single and multiple views under one framework
%  - discriminative training of indoor Manhattan models is possible


In this thesis we have presented ideas for inference of high--level
scene structure in the context of a moving observer. Drawing inspiration
from scene understanding ideas that have traditionally been the
purview of single--view computer vision, we have demonstrated a number
of promising approaches towards multiple--view scene understanding. In
this concluding chapter we will briefly review the key results and
present ideas for future work.

\section{Key Results}

\Chapref{appearance-only} presented textons as a simple and flexible
basis for inferring contextual variables such as scene
categories. Building on ideas from texture analysis, we presented a
probabilistic model and accompanying inference procedure, and
evaluated our approach on two classification problems. In both cases
our system out--performed the Gist descriptor of Torralba \etal.

In \chapref{geometry} we gave a formal account of the indoor Manhattan
model --- the first comprehensive analysis that we are aware of in the
literature (though not the first description \textit{per se}). This
chapter did not present any empirical results; its primary
contribution was the development of the ``vertex'' and ``seam''
representations, and the
decomposability property of indoor Manhattan scenes.

Next we discussed recovery of the Manhattan world's orientation with
respect to a camera, given multiple calibrated views of a scene. We
showed that reasoning from photometric information rather than
geometric information, and integrating multiple images into a joint
optimisation improved substantially upon existing approaches. Our
algorithm built upon ideas from single--view vanishing point
estimation; our contribution was in showing how to extend this to
multiple calibrated views.

\chapref{inference} focussed on inferring indoor Manhattan scene
structure from single and multiple views of a scene. We presented a
probabilistic model relating Manhattan scene structure to three sensor
modalities, and showed that the likelihoods for all three sensor
modalities can be written in terms of payoff functions. Beyond the
specific model that we proposed, this approach suggests a general
strategy by which further sensor modalities can be integrated with our
model without modifying the inference algorithm. The other
contribution of this chapter was the dynamic programming algorithm to
solve the payoff optimisation problem. We showed that a decomposition
into sub--problems permitted an efficient and exact solution to both
MAP and ML inference. Experiments in this chapter showed our system
substantially out--performing two other systems.

Finally, \chapref{learning} described an approach to learning indoor
Manhattan models from training examples. We described a structured
prediction learning algorithm for the indoor Manhattan hypothesis
class, and showed that the two required inference problems were
solvable by the dynamic programming algorithm of
\chapref{inference}. Among learning approaches to geometric scene
context, our contribution is among a small number that
implement a single optimisation with respect to a clearly defined loss
function. We showed a clear improvement over the system proposed in
\chapref{inference}.

A theme of this thesis has been the use of geometry for scene
understanding purposes. We have shown how to extract semantically
meaningful scene structure using ideas drawn from both the geometry
literature and the scene understanding literature. The ideas from
geometry allowed us to decompose our reconstructions into a
representation amenable to dynamic programming, and the ideas from
single--view scene understanding allowed us to connect our hypothesis
class to observed image features.

\section{Future Work}

In this section we discuss directions for future work.

\subsection{Applications of Indoor Manhattan Models}

Perhaps the clearest direction for future work is to apply the indoor
Manhattan model to the semantic inference tasks for which it was
originally designed, namely scene category recognition and contextual
object detection.

Scene category recognition is the problem of classifying scenes into
categories such as ``bedroom'', ``bathroom'', or ``office''. There is
a significant literature on this problem for the single--view case (as
reviewed in \chapref{review}), but little effort has been directed at
leveraging multiple--view geometry to this end. Since humans greatly
out--perform computers at this task, and humans appear to use various
notions of geometry to achieve their high performance, the use of
geometry for scene categorisation appears to be a particularly
compelling direction for future work.

Indoor Manhattan models could be leveraged for scene categorisation in
a number of ways. At the simplest level, one could recover an indoor
Manhattan representation for a query scene and compute a series of
geometric features to capture the shape of the scene (ratios of
length, breadth, and height, for example) and the position of the
camera within it. These could be appended to a vector of photometric
features (such as the many proposed in the single--view literature),
then a classic multiple--label classifier could be trained to
distinguish the various categories. A more sophisticated approach
might link the recovered geometry with photometric information more
closely. A typical photo captured by a camera located close to the
ceiling would be expected to appear different to that of a camera
located close to the floor, even within one scene
category. Photometric approaches rely on a classifier to learn such
variations automatically, but with an indoor Manhattan model at hand
one could model such variations explicitly. For example, one could
build up separate appearance models of the floor, wall, and ceilings,
using known scene geometry and camera position. Finally, the
possibility exists of improving upon simple Markovian models to
integrate information over time. A system that recognises when the
camera moves between rooms (such as by identifying doorways) could
segment a video sequence according to which frames are situated in
which rooms. Such a system could perform data association between
observations and room categories much more accurately than under a
hidden Markov model with a homogeneous transition function such as
that used in \cite{Torralba03}.

The second application to which we intend to apply indoor Manhattan
models is object recognition. Contextual information appears to
greatly improve object recognition (see \chapref{review} for a
review), and the prospect of leveraging the high--level geometric
information captured by the indoor Manhattan for this purpose seems
promising. A simple approach would be to append geometric features
derived from the recovered indoor Manhattan model to traditional
appearance features. These geometric features might include the
distance of the object from the floor plane (as a percentage of the
distance from floor to ceiling), the distance from the closest wall,
shape features of the environment, and so on. However, once again the
possibility exists of using Manhattan geometry in a more sophisticated
way. For example, one could integrate observations from different
viewpoints to improve the estimate of an object's identity. The
floorplan provided by an indoor Manhattan model could provide a
natural basis for integrating such observations.

Several robotics applications may also benefit from the ability to
recover Manhattan structure. Path planning requires knowledge of
``traversable'' surfaces in the environment as well as boundaries that
will obstruct movement. The floorplan provided by an indoor Manhattan
model seems a natural representation of such information. One might
divide the floor plane into a series of cells and separately estimate
traversability of each. The occupancy grid estimation might benefit
substantially from knowing the shape of the environment about each
cell.

A related to path planning is the problem of \textit{active
  exploration}, in which an agent must plan a path to find an object
or location of interest as quickly as possible. Typically this problem
is approached from the perspective of information gain rather than
shortest path. One might use Manhattan models as a basis for active
exploration by reasoning explicitly in terms of rooms and
corridors. For example, if a robot seeking a teapot recognises that it
is in a bathroom then it could move to a different room immediately,
not bothering to continue searching the current environment.

\subsection{Relaxing Geometric Constraints}

A common criticism levelled against indoor Manhattan models is the
strong geometric constraints that one must make. We have argued that
even in their present form, indoor Manhattan models are surprisingly
versatile. Nevertheless, there are several promising approaches to
relaxing these assumptions. The difficulty, of course, is finding
relaxations that retain the fast inference algorithm of
\chapref{inference}, which is based on the left--to--right
decomposability of indoor Manhattan models.

A first relaxation is to permit walls oriented in more than two
directions. This could be accomplished by identifying vanishing
points on the horizon line corresponding to additional wall
orientations, then extending the domain of the orientation variable in
the inference algorithm to account for these. These vanishing points
could be found either by clustering lines with respect to their
intersection at the horizon, or by modifying the rotation estimation
algorithm to jointly estimate these wall orientations together with
the scene orientation.

A second relaxation would be to permit walls that do not project to
straight lines on the floor plane. This could be accomplished in a
range of ways depending on the restriction that is chosen to replace
straightness. One could parametrise walls in pixel coordinates and
simply allow walls to change direction arbitrarily. While this would
permit a wide range of environments to be represented, it is not clear
that this is desirable since it removes the implicit penalisation of
highly complex models. A different approach would be to permit
parametric curves so that pillars and circular wall segments could be
represented. This could be accomplished without expanding the
state--space of the dynamic programming at all; it would simply entail
integrating the parametric family into the maximisation in
\eqnref{fin-split}.

Another promising direction for relaxation would be to target outdoor
areas by removing the assumption of a fixed ceiling plane. Many
built--up areas could be represented by a horizontal ground plane and
series of vertical facades. The key difference between indoor
environments is that building facades typically have varying
height. By adding a height parameter to the state space one could
jointly estimate the orientation and height of each facade using only
a slight modification to the algorithm presented in
\chapref{inference}.

\subsection{Extensions Of The Probabilistic Model}

In addition to the geometric extensions suggested above, there are
several promising ways in which the probabilistic models underlying
Manhattan structure recovery could be extended. In \chapref{learning}
we considered learning from labelled examples, but other types of
background information could also be helpful for fixing
parameters. For example, a database of architectural floorplans could
be leveraged to learn about the architectures an agent is most likely
to encounter, and hence to form a more accurate prior over building
structures. This would require a Bayesian model connecting
architectural floorplans to our prior over building structures

In a different direction, one might consider \textit{marginalizing}
over indoor Manhattan reconstructions for certain purposes rather than
just using a single MAP estimate. That is, for the purpose of, say,
scene categorisation or object search, we would consider \textit{all}
possible indoor Manhattan reconstructions and their implications for
the task at hand, weighted by their plausibility under the model
presented in \chapref{inference}. In this case we would see the
reconstruction as a latent variable. In many cases such a
marginalisation is intractable, but in the case of indoor Manhattan
models there is a promising approach by which the decomposition of
\chapref{inference} might be leveraged to perform exact
marginalisation for a large family of models.

Finally, there is much room for integrating the estimation of indoor
Manhattan models over time. Currently our inference procedure is a
batch operation that re--estimates the model from scratch at each time
step. Extending this to a recursive estimation framework would allow
us to integrate new information in a more principled way, and avoid
discarding the computational effort invested at previous time
steps. Recursive state estimators maintain a distribution over an
underlying hypothesis class that can be efficiently updated from new
evidence. A filter for indoor Manhattan environments might represent
hypotheses in the seam representation discussed in chapter
\chapref{geometry} and summarise a distribution over this space using
a payoff matrix as discussed in \chapref{inference}. Updating the
payoff matrix over time requires integrating image evidence from new
viewpoints, but we have already presented the basic geometry that such
updates would require during our discussion of stereo features in
\chapref{inference}. Significant work would be required to deal with
the occlusion artefacts that integrating information over long periods
would introduce.

\section{Final Remarks}

The meeting between geometric ideas from structure--from--motion and
scene understanding ideas from single view computer vision seems to
hold promise as an exciting research direction over the coming
years. This will be driven as much by the new sensor modalities
discussed in the introduction as by the maturity of both existing
SLAM systems and scene understanding as separate areas of study. We
look forward to seeing this unfold.

